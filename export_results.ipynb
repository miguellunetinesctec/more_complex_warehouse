{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library imports\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from stable_baselines3 import PPO, DQN\n",
    "\n",
    "from env import WarehouseEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_episode(env, policy_function):\n",
    "\n",
    "    state, info = env.reset()\n",
    "\n",
    "    done = False   \n",
    "    final_reward = 0\n",
    "     \n",
    "    while not done:\n",
    "        action = policy_function(state)\n",
    "        state, reward, done, done, _ = env.step(action)\n",
    "        final_reward += reward\n",
    "    \n",
    "    avg_dos_section_a = env.avg_dos_section_a\n",
    "    avg_dos_section_b = env.avg_dos_section_b\n",
    "    avg_dos_section_c = env.avg_dos_section_c\n",
    "            \n",
    "    return final_reward, avg_dos_section_a, avg_dos_section_b, avg_dos_section_c\n",
    "\n",
    "#Evaluate the policy\n",
    "def evaluate_policy(env, policy_function, num_episodes):\n",
    "\n",
    "    list_final_reward = []\n",
    "    list_avg_dos_section_a = []\n",
    "    list_avg_dos_section_b = []\n",
    "    list_avg_dos_section_c = []\n",
    "\n",
    "    for i in range(num_episodes):\n",
    "\n",
    "        print(f\"Episode {i+1}/{num_episodes}\")\n",
    "\n",
    "        env.update_seed(i)\n",
    "        final_reward, avg_dos_section_a, avg_dos_section_b, avg_dos_section_c = run_episode(env, policy_function)\n",
    "        list_final_reward.append(final_reward)\n",
    "        list_avg_dos_section_a.append(avg_dos_section_a)\n",
    "        list_avg_dos_section_b.append(avg_dos_section_b)\n",
    "        list_avg_dos_section_c.append(avg_dos_section_c)\n",
    "        \n",
    "    return np.mean(list_final_reward), np.std(list_final_reward), np.mean(list_avg_dos_section_a), np.mean(list_avg_dos_section_b), np.mean(list_avg_dos_section_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_results():\n",
    "\n",
    "    results = []\n",
    "\n",
    "    from tensorflow.keras.models import load_model\n",
    "\n",
    "    env = WarehouseEnv()\n",
    "\n",
    "    def get_state(state):\n",
    "        return state\n",
    "\n",
    "    def rl_get_state(state):\n",
    "        \n",
    "        data_rows = []\n",
    "\n",
    "        for i in range(env.num_sectors):\n",
    "            data_rows.append(state['capacity'][i]/state['static_info']['max_capacity'][i])\n",
    "\n",
    "        dos = state['static_info']['dos']\n",
    "        dos_min = min(dos)\n",
    "        dos_max = max(dos)\n",
    "            \n",
    "        if dos_max == dos_min:\n",
    "            normalized_dos = 0  # or 1 â€” depends on how you want to handle it\n",
    "        else:\n",
    "            normalized_dos = (dos[env.current_product] - dos_min) / (dos_max - dos_min)\n",
    "        \n",
    "        data_rows.append(normalized_dos)\n",
    "        #Truncate the data to be between 0 and 1\n",
    "        #data_rows = np.clip(data_rows, 0, 1)\n",
    "        \n",
    "        return np.array(np.nan_to_num(data_rows, nan=0), dtype=np.float32)\n",
    "        \n",
    "\n",
    "\n",
    "    num_episodes = 20\n",
    "    policy_names = ['random', 'ABC', 'A-first', 'dqn', 'ppo', 'maskable_ppo']\n",
    "    #policy_names = ['random', 'dqn']\n",
    "\n",
    "    for policy_name in policy_names:\n",
    "\n",
    "        print(f\"Evaluating policy: {policy_name}\")\n",
    "\n",
    "        if policy_name == \"random\":\n",
    "\n",
    "            env.get_state = get_state\n",
    "\n",
    "            def policy(state):\n",
    "                possible_actions = [i for i, capacity in enumerate(state['capacity']) if capacity > 0]\n",
    "                action = random.choice(possible_actions)\n",
    "                return action\n",
    "            mean_reward, std_reward, avg_a, avg_b, avg_c = evaluate_policy(env, policy, num_episodes) \n",
    "        \n",
    "        elif policy_name == \"ABC\":\n",
    "\n",
    "            env.get_state = get_state\n",
    "\n",
    "            def policy(state):\n",
    "                if state['current_product'] == 0:\n",
    "                    if state['capacity'][0] > 0:\n",
    "                        action = 0\n",
    "                    elif state['capacity'][1] > 0:\n",
    "                        action = 1\n",
    "                    else:\n",
    "                        action = 2\n",
    "                elif state['current_product'] == 1 or state['current_product'] == 2:\n",
    "                    if state['capacity'][1] > 0:\n",
    "                        action = 1\n",
    "                    elif state['capacity'][2] > 0:\n",
    "                        action = 2\n",
    "                    else:\n",
    "                        action = 0\n",
    "                elif state['current_product'] == 3 or state['current_product'] == 4 or state['current_product'] == 5:\n",
    "                    if state['capacity'][2] > 0:\n",
    "                        action = 2\n",
    "                    elif state['capacity'][1] > 0:\n",
    "                        action = 1\n",
    "                    else:\n",
    "                        action = 0\n",
    "                else:\n",
    "                    action = 0\n",
    "                return action\n",
    "            \n",
    "            mean_reward, std_reward, avg_a, avg_b, avg_c = evaluate_policy(env, policy, num_episodes) \n",
    "\n",
    "        elif policy_name == \"A-first\":\n",
    "\n",
    "            env.get_state = get_state\n",
    "\n",
    "            def policy(state):\n",
    "                if state['capacity'][0] > 0:\n",
    "                    action = 0\n",
    "                elif state['capacity'][1] > 0:\n",
    "                    action = 1\n",
    "                else:\n",
    "                    action = 2\n",
    "                return action\n",
    "            \n",
    "            mean_reward, std_reward, avg_a, avg_b, avg_c = evaluate_policy(env, policy, num_episodes) \n",
    "\n",
    "    \n",
    "        elif policy_name == \"dqn\":\n",
    "\n",
    "            model = DQN.load(f\"rl_models/dqn_models/dqn_model\")\n",
    "            \n",
    "            env.get_state = rl_get_state\n",
    "\n",
    "            def policy(state):\n",
    "                action, _ = model.predict(state, deterministic=True)\n",
    "                action = int(action)\n",
    "                return action\n",
    "            \n",
    "            mean_reward, std_reward, avg_a, avg_b, avg_c = evaluate_policy(env, policy, num_episodes) \n",
    "        \n",
    "        elif policy_name == \"ppo\":\n",
    "\n",
    "            model = PPO.load(f\"rl_models/ppo_models/ppo_model\")\n",
    "            \n",
    "            env.get_state = rl_get_state\n",
    "\n",
    "            def policy(state):\n",
    "                action, _ = model.predict(state, deterministic=True)\n",
    "                action = int(action)\n",
    "                return action\n",
    "            \n",
    "            mean_reward, std_reward, avg_a, avg_b, avg_c = evaluate_policy(env, policy, num_episodes) \n",
    "        \n",
    "        elif policy_name == \"maskable_ppo\":\n",
    "            \n",
    "            from sb3_contrib import MaskablePPO\n",
    "            from sb3_contrib.common.maskable.utils import get_action_masks\n",
    "            model = MaskablePPO.load(f\"rl_models/maskable_ppo_models/maskable_ppo_model\")\n",
    "\n",
    "            env.get_state = rl_get_state\n",
    "\n",
    "            def policy(state):\n",
    "                action_masks = get_action_masks(env)\n",
    "                action, _ = model.predict(observation=state, deterministic=True, action_masks=action_masks)\n",
    "                action = int(action)\n",
    "                return action\n",
    "            mean_reward, std_reward, avg_a, avg_b, avg_c = evaluate_policy(env, policy, num_episodes)\n",
    "            \n",
    "\n",
    "        results.append({\n",
    "            'Policy': policy_name,\n",
    "            'MeanReward': np.round(mean_reward,2),\n",
    "            'StdReward': np.round(std_reward,2),\n",
    "            'AvgDosSectionA': np.round(avg_a,2),\n",
    "            'AvgDosSectionB': np.round(avg_b,2),\n",
    "            'AvgDosSectionC': np.round(avg_c,2)\n",
    "        })\n",
    "\n",
    "    # Convert the results list to a DataFrame\n",
    "    results_df = pd.DataFrame(results)\n",
    "\n",
    "    import os\n",
    "\n",
    "    # Save the results to a CSV file\n",
    "    results_df.to_csv(f'results/tables/table_results.csv', mode='a', header=not os.path.exists(f'results/tables/table.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating policy: random\n",
      "Episode 1/20\n",
      "Episode 2/20\n",
      "Episode 3/20\n",
      "Episode 4/20\n",
      "Episode 5/20\n",
      "Episode 6/20\n",
      "Episode 7/20\n",
      "Episode 8/20\n",
      "Episode 9/20\n",
      "Episode 10/20\n",
      "Episode 11/20\n",
      "Episode 12/20\n",
      "Episode 13/20\n",
      "Episode 14/20\n",
      "Episode 15/20\n",
      "Episode 16/20\n",
      "Episode 17/20\n",
      "Episode 18/20\n",
      "Episode 19/20\n",
      "Episode 20/20\n",
      "Evaluating policy: ABC\n",
      "Episode 1/20\n",
      "Episode 2/20\n",
      "Episode 3/20\n",
      "Episode 4/20\n",
      "Episode 5/20\n",
      "Episode 6/20\n",
      "Episode 7/20\n",
      "Episode 8/20\n",
      "Episode 9/20\n",
      "Episode 10/20\n",
      "Episode 11/20\n",
      "Episode 12/20\n",
      "Episode 13/20\n",
      "Episode 14/20\n",
      "Episode 15/20\n",
      "Episode 16/20\n",
      "Episode 17/20\n",
      "Episode 18/20\n",
      "Episode 19/20\n",
      "Episode 20/20\n",
      "Evaluating policy: A-first\n",
      "Episode 1/20\n",
      "Episode 2/20\n",
      "Episode 3/20\n",
      "Episode 4/20\n",
      "Episode 5/20\n",
      "Episode 6/20\n",
      "Episode 7/20\n",
      "Episode 8/20\n",
      "Episode 9/20\n",
      "Episode 10/20\n",
      "Episode 11/20\n",
      "Episode 12/20\n",
      "Episode 13/20\n",
      "Episode 14/20\n",
      "Episode 15/20\n",
      "Episode 16/20\n",
      "Episode 17/20\n",
      "Episode 18/20\n",
      "Episode 19/20\n",
      "Episode 20/20\n",
      "Evaluating policy: dqn\n",
      "Episode 1/20\n",
      "Episode 2/20\n",
      "Episode 3/20\n",
      "Episode 4/20\n",
      "Episode 5/20\n",
      "Episode 6/20\n",
      "Episode 7/20\n",
      "Episode 8/20\n",
      "Episode 9/20\n",
      "Episode 10/20\n",
      "Episode 11/20\n",
      "Episode 12/20\n",
      "Episode 13/20\n",
      "Episode 14/20\n",
      "Episode 15/20\n",
      "Episode 16/20\n",
      "Episode 17/20\n",
      "Episode 18/20\n",
      "Episode 19/20\n",
      "Episode 20/20\n",
      "Evaluating policy: ppo\n",
      "Episode 1/20\n",
      "Episode 2/20\n",
      "Episode 3/20\n",
      "Episode 4/20\n",
      "Episode 5/20\n",
      "Episode 6/20\n",
      "Episode 7/20\n",
      "Episode 8/20\n",
      "Episode 9/20\n",
      "Episode 10/20\n",
      "Episode 11/20\n",
      "Episode 12/20\n",
      "Episode 13/20\n",
      "Episode 14/20\n",
      "Episode 15/20\n",
      "Episode 16/20\n",
      "Episode 17/20\n",
      "Episode 18/20\n",
      "Episode 19/20\n",
      "Episode 20/20\n",
      "Evaluating policy: maskable_ppo\n",
      "Episode 1/20\n",
      "Episode 2/20\n",
      "Episode 3/20\n",
      "Episode 4/20\n",
      "Episode 5/20\n",
      "Episode 6/20\n",
      "Episode 7/20\n",
      "Episode 8/20\n",
      "Episode 9/20\n",
      "Episode 10/20\n",
      "Episode 11/20\n",
      "Episode 12/20\n",
      "Episode 13/20\n",
      "Episode 14/20\n",
      "Episode 15/20\n",
      "Episode 16/20\n",
      "Episode 17/20\n",
      "Episode 18/20\n",
      "Episode 19/20\n",
      "Episode 20/20\n"
     ]
    }
   ],
   "source": [
    "export_results()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
